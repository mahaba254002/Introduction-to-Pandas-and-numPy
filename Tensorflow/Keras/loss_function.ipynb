{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loss Function\n",
    "- It is a function that compares the target and predicted output values; measures how well the neural network models the training data. When training, we aim to minimize this loss between the predicted and target outputs.\n",
    "- The goal of training a CNN is to minimize this loss function, which is achieved through an optimization process\n",
    "- For regression most common loss function is mse while classification it is Categorical Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optimizers\n",
    "- Are algorithms used to update the parameters of a neural network during the training process in order to minimize the loss function.\n",
    "- They determine how the weights and biases of the network are adjusted based on the computed gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Metrics\n",
    "- Are evaluation measures used to assess the performance of a model\n",
    "- Accuracy: used metric for classification tasks. It measures the proportion of correctly predicted samples out of the total number of samples. However, accuracy can be misleading when the classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Backpropagation\n",
    "- An algorithm created to test error which will travel back from input nodes to output nodes.\n",
    "- It is applied to improve accuracy in data mining in machine learning\n",
    "- In CNN it is the process of computing the gradients of the loss function with respect to the parameters of the CNN.\n",
    "- It allows the network to learn from the errors and update its parameters accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Epoch\n",
    "- It refers to a complete pass of the entire training dataset through the neural network\n",
    "- A complete forward pass (forward propagation) and a backward pass (backpropagation) through the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Batch size\n",
    "- Batch size refers to the number of training examples (samples) that are processed together in one forward and backward pass during training\n",
    "- Larger batch size result in faster progress in training. But dont always converge fast\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider A neural network with dataset 3000 images,batch size 32 and 500 epochs.\n",
    "- The batch size is set to 32. This means that during training, the neural network will process 32 images at a time before updating its parameters based on the computed gradients. The dataset will be divided into batches of size 32, resulting in 3000/32 = 94 iteration.meaning each epoch has 94 iterations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
